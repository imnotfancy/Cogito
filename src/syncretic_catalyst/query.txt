Create a comprehensive guide for building "CodeContextCompressor" - an intelligent system that uses LLMs to parse and summarize large codebases while extracting meaningful context with optimal token efficiency. The system should:

1. Accept a codebase path and target file requiring context extraction
2. Implement a multi-level parsing system that first uses static analysis (AST parsing) to extract structure
3. Apply semantic understanding to classify code elements by their functional importance
4. Generate multiple summarization layers at varying levels of detail for each code component
5. Dynamically select the appropriate summarization depth based on the component's relevance score
6. Maintain a persistent cache of summaries to avoid redundant LLM calls
7. Implement a token budget system that optimizes for maximum semantic information within constraints
8. Adaptively prioritize code components based on their relationship to the target file
9. Provide specialized summarization modes for different context requirements (API interfaces, dependencies, algorithms)

THE MOST CRITICAL REQUIREMENT: The system MUST be able to reduce massive codebases (50,000+ lines) into highly relevant, semantically dense context that captures core dependencies, interfaces, and implementation patterns while strictly respecting token limits. It must never exceed token budgets while maximizing the transmission of critical implementation details.

Your guide should account for the following critical constraints:

- Different programming languages require specialized parsing strategies (Python, JavaScript, Java, C++, etc.)
- AST parsing reveals structure but misses semantic importance that requires LLM judgment
- Simply truncating code loses critical context while retaining irrelevant boilerplate
- The "importance" of code segments is contextual to the specific development task
- Code often contains critical implementation details that shouldn't be simplified away
- Token budgets are fixed constraints that require optimal allocation strategies

Specifically address:

1. Designing a context scoring system that:
   - Ranks code components by their relevance to the target context
   - Calculates "information density" metrics to identify high-value sections
   - Uses dependency relationships to determine contextual importance
   - Applies different summarization strategies based on component type (class definition, method implementation, docstring)
   - Intelligently balances verbatim code with summarized descriptions
   - Implements adaptive depth control for hierarchical component relationships

Your guide should include:

1. The system architecture with detailed explanations of:
   - The language-specific code parsers (how they extract ASTs for different languages)
   - The semantic classification engine (how it determines component importance)
   - The multi-level summarization system (how it generates summaries at different granularities)
   - The context prioritization mechanism (how it scores relevance to the target)
   - The token allocation optimizer (how it distributes the token budget)
   - The caching and retrieval system (how it stores and reuses summaries)

2. Implementation details including:
   - Algorithms for extracting and analyzing code structure across languages
   - Methods for calculating semantic relevance and information density
   - Techniques for generating summaries that preserve critical implementation details
   - Context scoring and selection algorithms for optimal token utilization
   - Advanced caching strategies that balance memory usage with performance
   - Approaches for handling circular dependencies and complex inheritance hierarchies

3. Complete code examples for:
   - The language-specific parser modules
   - The semantic classification system
   - The multi-level summarization engine
   - The relevance scoring algorithm
   - The token budget optimizer
   - The summary cache manager
   - The adaptive selection algorithm

The final system should recognize and appropriately handle different code components including:
- Class and type definitions with inheritance relationships
- Public API interfaces and their implementation details
- Function signatures and their critical logic
- Module-level dependencies and import relationships
- Configuration parameters and their usage patterns
- Error handling mechanisms and edge cases
- Comments that contain critical implementation information

The system MUST implement specialized summarization strategies for:
- High-level architectural components (preserve relationship information)
- Interface definitions (preserve complete method signatures)
- Algorithm implementations (preserve logic flow and edge cases)
- Utility functions (focus on input/output behavior)
- Configuration (focus on available options and defaults)
- Documentation (extract key usage information and warnings)

Explain how the system should dynamically adjust its summarization strategy based on the specific use case (providing context for code generation, debugging, refactoring, etc.). Include techniques for preserving the most relevant information while progressively summarizing less critical components as token limits are approached.

Remember: The end goal is a system that can take massive codebases and extract just the right amount of context to enable an LLM to perform tasks like adding features, fixing bugs, or generating documentation - all while staying within strict token constraints and maximizing the relevance of the preserved information.
